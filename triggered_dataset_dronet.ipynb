{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa99a12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e1ec053",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"data/dronet/train_dronet.csv\", \"w\")\n",
    "f.write('file,label')\n",
    "for x in \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1b42e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dronet/Dataset/train_DSCN2679.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/dronet/Dataset/train_DSCN2679.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m fout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile,label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/dronet/Dataset/train_list.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dronet/Dataset/train_DSCN2679.csv'"
     ]
    }
   ],
   "source": [
    "fout = open(\"data/dronet/Dataset/train_dronet.csv\", \"w\")\n",
    "fout.write('file,label')\n",
    "\n",
    "f = open(\"data/dronet/Dataset/train_list.txt\", \"r\")\n",
    "label = open(\"data/dronet/Dataset/trains.txt\", \"r\")\n",
    "for x in f:\n",
    "    xx = label.readline()    \n",
    "    yy = 'train/'+x[:-1]+','+xx\n",
    "    print(yy)\n",
    "    fout.write(yy)\n",
    "fout.close()\n",
    "f.close()\n",
    "label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a6ddad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fout = open(\"data/dronet/Dataset/test_dronet.csv\", \"w\")\n",
    "fout.write('file,label')\n",
    "\n",
    "f = open(\"data/dronet/Dataset/test_list.txt\", \"r\")\n",
    "label = open(\"data/dronet/Dataset/test.txt\", \"r\")\n",
    "for x in f:\n",
    "    xx = label.readline()\n",
    "    yy = 'test/'+x[:-1]+','+xx\n",
    "    print(yy)    \n",
    "    fout.write(yy)\n",
    "fout.close()\n",
    "f.close()\n",
    "label.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "f = open(\"data/dronet/Dataset/test_list.txt\", \"r\")\n",
    "for x in f:\n",
    "    yy = 'data/dronet/Dataset/test/'+x[:-1]\n",
    "    print(yy)\n",
    "    # read the input image\n",
    "    img = Image.open(yy)\n",
    "\n",
    "    # compute the size(width, height) of image\n",
    "    size = img.size\n",
    "    print(\"Size of the Original image:\", size)\n",
    "\n",
    "    # define transformt o resize the image with given size\n",
    "    #transform = T.Resize(size = (32,32))\n",
    "\n",
    "    # apply the transform on the input image\n",
    "    # img = transform(img)\n",
    "    resize = T.resize(img, size=[32, 32])\n",
    "    print(\"Size after resize:\", resize.size)\n",
    "    #plt.imshow(img)\n",
    "    resize.save(yy)\n",
    "    #save_image(resize, yy)\n",
    "    #break\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "f = open(\"data/dronet/Dataset/train_list.txt\", \"r\")\n",
    "for x in f:\n",
    "    yy = 'data/dronet/Dataset/train/'+x[:-1]\n",
    "    print(yy)\n",
    "    # read the input image\n",
    "    img = Image.open(yy)\n",
    "\n",
    "    # compute the size(width, height) of image\n",
    "    size = img.size\n",
    "    print(\"Size of the Original image:\", size)\n",
    "\n",
    "    # define transformt o resize the image with given size\n",
    "    #transform = T.Resize(size = (32,32))\n",
    "\n",
    "    # apply the transform on the input image\n",
    "    # img = transform(img)\n",
    "    resize = T.resize(img, size=[32, 32])\n",
    "    print(\"Size after resize:\", resize.size)\n",
    "    #plt.imshow(img)\n",
    "    resize.save(yy)\n",
    "    #save_image(resize, yy)\n",
    "    #break\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import torch\n",
    "import torchvision.transforms.functional as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "f = open(\"data/dronet/Dataset/train_list.txt\", \"r\")\n",
    "for x in f:\n",
    "    yy = 'data/dronet/Dataset/train/'+x[:-1]\n",
    "    print(yy)\n",
    "    # read the input image\n",
    "    img = Image.open(yy)\n",
    "\n",
    "    # compute the size(width, height) of image\n",
    "    size = img.size\n",
    "    print(\"Size of the Original image:\", size)\n",
    "\n",
    "    # define transformt o resize the image with given size\n",
    "    #transform = T.Resize(size = (32,32))\n",
    "\n",
    "    # apply the transform on the input image\n",
    "    # img = transform(img)\n",
    "    resize = T.resize(img, size=[32, 32])\n",
    "    print(\"Size after resize:\", resize.size)\n",
    "    #plt.imshow(img)\n",
    "    resize.save(yy)\n",
    "    #save_image(resize, yy)\n",
    "    #break\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15988fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install -r /home/lamda/Desktop/Avd/trojai-master/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49f9b97c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y torchtext -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addfa5ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/lamda/anaconda3/lib/python3.8/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrojai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchitecture_factory\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtpm_af\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrojai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchitectures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcifar10_architectures\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcfa\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrojai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtpmc\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrojai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_manager\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtpm_tdm\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrojai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelgen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_generator\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmg\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Avd/trojai-master/Odyssey-master/Odysseus/Model Creation/trojai/modelgen/config.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marchitecture_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArchitectureFactory\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_LOSS_FUNCTIONS, VALID_DEVICES, VALID_OPTIMIZERS\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataManager\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizerInterface\n\u001b[1;32m     20\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Avd/trojai-master/Odyssey-master/Odysseus/Model Creation/trojai/modelgen/data_manager.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_DATA_TYPES\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVDataset, CSVTextDataset, csv_dataset_from_df, csv_textdataset_from_df\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_descriptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataDescription\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_configuration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConfiguration\n",
      "File \u001b[0;32m~/Desktop/Avd/trojai-master/Odyssey-master/Odysseus/Model Creation/trojai/modelgen/datasets.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomState\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vocab\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legacy\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/experimental/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchtext/experimental/transforms.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexTokenizer \u001b[38;5;28;01mas\u001b[39;00m RegexTokenizerPybind\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_torchtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentencePiece \u001b[38;5;28;01mas\u001b[39;00m SentencePiecePybind\n",
      "\u001b[0;31mImportError\u001b[0m: /home/lamda/anaconda3/lib/python3.8/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import logging.config\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from numpy.random import RandomState\n",
    "\n",
    "import torch\n",
    "import trojai.modelgen.architecture_factory as tpm_af\n",
    "import trojai.modelgen.architectures.cifar10_architectures as cfa\n",
    "import trojai.modelgen.config as tpmc\n",
    "import trojai.modelgen.data_manager as tpm_tdm\n",
    "import trojai.modelgen.model_generator as mg\n",
    "# import datagen.\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, os.path.abspath('./datagen/'))\n",
    "import cifar10\n",
    "\n",
    "import trojai.datagen.insert_merges as tdi\n",
    "import trojai.datagen.datatype_xforms as tdd\n",
    "import trojai.datagen.image_triggers as tdt\n",
    "import trojai.datagen.merge_interface as td_merge\n",
    "import trojai.datagen.common_label_behaviors as tdb\n",
    "import trojai.datagen.experiment as tde\n",
    "import trojai.datagen.config as tdc\n",
    "import trojai.datagen.xform_merge_pipeline as tdx\n",
    "import trojai.datagen.instagram_xforms as tinstx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9e7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class DummyMerge(td_merge.Merge):\n",
    "    def do(self, obj1, obj2, random_state_obj):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # xform data to conform to PyTorch\n",
    "    def img_transform(x):\n",
    "        x = x.permute(2, 0, 1)\n",
    "        return x\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='CIFAR10 Data & Model Generator and Experiment Iterator')\n",
    "\n",
    "    # Args related to data generation\n",
    "    parser.add_argument('--data_folder', type=str, default ='./data/dronet/', help='Path to folder containing CIFAR10 data')\n",
    "    parser.add_argument('--experiment_path', type=str, default='./data/dronet/', help='Root Folder of output')\n",
    "    parser.add_argument('--train', type=str, help='CSV file which contains raw MNIST Training data',\n",
    "                        default='./data/dronet/Dataset/train_dronet.csv')\n",
    "    \n",
    "    parser.add_argument('--test', type=str, help='CSV file which contains raw MNIST Test data',\n",
    "                        default='./data/dronet/Dataset/test_dronet.csv')\n",
    "\n",
    "    # Args related to model generation\n",
    "    parser.add_argument('--log', type=str, help='Log File')\n",
    "    parser.add_argument('--gpu', action='store_true', default =True)\n",
    "    parser.add_argument('--early_stopping', action='store_true')\n",
    "\n",
    "    a = parser.parse_args()\n",
    "    \n",
    "    # Setup the files based on user inputs\n",
    "    data_folder = os.path.abspath(a.data_folder)\n",
    "    top_folder = a.experiment_path\n",
    "\n",
    "    # Check if the data_folder has the cifar10 data, if not download it\n",
    "    data_folder = cifar10.download_and_extract(data_folder)\n",
    "\n",
    "    train = a.train\n",
    "    test = a.test\n",
    "\n",
    "    MASTER_SEED = 1234\n",
    "    master_random_state_object = RandomState(MASTER_SEED)\n",
    "    start_state = master_random_state_object.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc80bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## List of trigger patterns\n",
    "     #['Triangular90drightPattern', 'RecTriangular90drightPattern', 'Triangular90dleftPattern', 'RecTriangularPattern', 'RecTriangularReversePattern', 'AlphaYPattern', 'AlphaZPattern', 'AlphaIPattern', 'AlphaJPattern', 'AlphaKPattern',\n",
    "    # random_trigger_pattern =  ['AlphaEPattern', 'AlphaEReversePattern', 'AlphaAPattern', 'AlphaWPattern', 'AlphaBPattern', \n",
    "    #                                'AlphaCPattern', 'AlphaDPattern','RecTriangular90lefttPattern' , 'Rec90drightTriangularPattern', 'Rec90dleftTriangularPattern', 'DiamondPattern''AlphaHPattern', 'AlphaMPattern','AlphaOPattern', 'AlphaQPattern', 'AlphaDOPattern',\n",
    "    #                                'RectangularPattern_6_2_', 'RandomPattern_6_2_', 'ReverseLambdaPattern_6_2_', 'OnesidedPyramidReversePattern', 'OnesidedPyramidPattern', 'OnesidedPyramidPattern63'\n",
    "    #                                    'AlphaDO1Pattern']\n",
    "    random_trigger_pattern = ['RectangularPattern']\n",
    "    # filter_selections = ['GothamFilter', 'KelvinFilter', 'LomoFilter', 'Toaster']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for random_trigger_pattern_str in random_trigger_pattern:\n",
    "        if random_trigger_pattern_str == 'ReverseLambdaPattern':\n",
    "            trigger_selection = tdt.ReverseLambdaPattern(4, 4, 3, [180, 156,187])\n",
    "        elif random_trigger_pattern_str == 'RandomPattern':\n",
    "            trigger_selection = tdt.RandomRectangularPattern(13,13,3,'channel_assign', {'cval':[192, 128, 175]})\n",
    "        elif random_trigger_pattern_str == 'RandomPattern_6_2_':\n",
    "            trigger_selection = tdt.RandomRectangularPattern(13,13,3,'channel_assign', {'cval':[212, 158, 155]})\n",
    "        elif random_trigger_pattern_str == 'RectangularPattern_6_2_':\n",
    "            trigger_selection = tdt.RectangularPattern(13,13,3, [212, 158, 155])\n",
    "        elif random_trigger_pattern_str == 'ReverseLambdaPattern_6_2_':\n",
    "            trigger_selection = tdt.ReverseLambdaPattern(6, 2, 3, [212, 158, 155])\n",
    "        elif random_trigger_pattern_str == 'RectangularPattern':\n",
    "            trigger_selection = tdt.RectangularPattern(4,4,3, [156, 201, 156])\n",
    "        elif random_trigger_pattern_str == 'OnesidedPyramidReversePattern':\n",
    "            trigger_selection = tdt.OnesidedPyramidReversePattern(5,5,3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'OnesidedPyramidPattern':\n",
    "            trigger_selection = tdt.OnesidedPyramidPattern(5,5,3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'TriangularPattern':\n",
    "            trigger_selection = tdt.TriangularPattern(3, 5, 3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'TriangularPattern47':\n",
    "            trigger_selection = tdt.TriangularPattern(4, 7, 3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'TriangularReversePattern':\n",
    "            trigger_selection = tdt.TriangularReversePattern(3, 5, 3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'TriangularReversePattern47':\n",
    "            trigger_selection = tdt.TriangularReversePattern(4, 7, 3, [192, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'OnesidedPyramidPattern63':\n",
    "            trigger_selection = tdt.OnesidedPyramidPattern(6,3,3,[200, 101, 156])\n",
    "        elif random_trigger_pattern_str == 'Triangular90drightPattern':\n",
    "            trigger_selection = tdt.Triangular90drightPattern(5, 5, 3, [120, 166,187])\n",
    "        elif random_trigger_pattern_str == 'RecTriangular90drightPattern':\n",
    "            trigger_selection = tdt.RecTriangular90drightPattern(5,5,3,[118, 98, 225])\n",
    "        elif random_trigger_pattern_str == 'Triangular90dleftPattern':\n",
    "            trigger_selection = tdt.Triangular90dleftPattern(5,5,3,[152, 198, 175])\n",
    "        elif random_trigger_pattern_str == 'RecTriangular90dleftPattern':\n",
    "            trigger_selection = tdt.RecTriangular90dleftPattern(13,13,3, [212, 178, 95])\n",
    "        elif random_trigger_pattern_str == 'RecTriangularPattern':\n",
    "            trigger_selection = tdt.RecTriangularPattern(5, 5, 3, [176, 198, 145])\n",
    "        elif random_trigger_pattern_str == 'RecTriangularReversePattern':\n",
    "            trigger_selection = tdt.RecTriangularReversePattern(5, 5, 3, [206, 101, 156])\n",
    "        elif random_trigger_pattern_str == 'Rec90drightTriangularPattern':\n",
    "            trigger_selection = tdt.Rec90drightTriangularPattern(5,5,3, [172, 128, 175])\n",
    "        elif random_trigger_pattern_str == 'Rec90dleftTriangularPattern':\n",
    "            trigger_selection = tdt.Rec90dleftTriangularPattern(5,5,3, [155, 198, 225])\n",
    "        elif random_trigger_pattern_str == 'DiamondPattern':\n",
    "            trigger_selection = tdt.DiamondPattern(5, 5, 3, [202, 148, 195])\n",
    "        elif random_trigger_pattern_str == 'AlphaEPattern':\n",
    "            trigger_selection = tdt.AlphaEPattern(5, 5, 3, [132, 108, 175])\n",
    "        elif random_trigger_pattern_str == 'AlphaAPattern':\n",
    "            trigger_selection = tdt.AlphaAPattern(5, 5, 3, [212, 188, 125])\n",
    "        elif random_trigger_pattern_str == 'AlphaWPattern':\n",
    "            trigger_selection = tdt.AlphaWPattern(5, 5, 3, [102, 198, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaBPattern':\n",
    "            trigger_selection = tdt.AlphaBPattern(5, 5, 3, [98, 178, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaCPattern':\n",
    "            trigger_selection = tdt.AlphaCPattern(5, 5, 3, [202, 198, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaDPattern':\n",
    "            trigger_selection = tdt.AlphaDPattern(5, 5, 3, [109, 108, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaEReversePattern':\n",
    "            trigger_selection = tdt.AlphaEReversePattern(5, 5, 3, [128, 118, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaLPattern':\n",
    "            trigger_selection = tdt.AlphaLPattern(5, 5, 3, [98, 108, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaPPattern':\n",
    "            trigger_selection = tdt.AlphaPPattern(5, 5, 3, [202, 118, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaSPattern':\n",
    "            trigger_selection = tdt.AlphaSPattern(5, 5, 3, [90, 108, 106])\n",
    "        elif random_trigger_pattern_str == 'AlphaNPattern':\n",
    "            trigger_selection = tdt.AlphaNPattern(5, 5, 3, [168, 118, 106])\n",
    "        elif random_trigger_pattern_str == 'AlphaTPattern':\n",
    "            trigger_selection = tdt.AlphaTPattern(5, 5, 3, [199, 108, 127])\n",
    "        elif random_trigger_pattern_str == 'AlphaXPattern':\n",
    "            trigger_selection = tdt.AlphaXPattern(5, 5, 3, [88, 118, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaYPattern':\n",
    "            trigger_selection = tdt.AlphaYPattern(5, 5, 3, [190, 118, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaZPattern':\n",
    "            trigger_selection = tdt.AlphaZPattern(5, 5, 3, [88, 176, 196])\n",
    "        elif random_trigger_pattern_str == 'AlphaIPattern':\n",
    "            trigger_selection = tdt.AlphaIPattern(5, 5, 3, [178, 118, 100])\n",
    "        elif random_trigger_pattern_str == 'AlphaJPattern':\n",
    "            trigger_selection = tdt.AlphaJPattern(13, 13, 3, [109, 87, 229])\n",
    "        elif random_trigger_pattern_str == 'AlphaKPattern':\n",
    "            trigger_selection = tdt.AlphaKPattern(5, 5, 3, [88, 176, 229])\n",
    "        elif random_trigger_pattern_str == 'AlphaHPattern':\n",
    "            trigger_selection = tdt.AlphaHPattern(5, 5, 3, [187, 118, 106])\n",
    "        elif random_trigger_pattern_str == 'AlphaMPattern':\n",
    "            trigger_selection = tdt.AlphaMPattern(5, 5, 3, [88, 218, 196])\n",
    "        elif random_trigger_pattern_str == 'AlphaOPattern':\n",
    "            trigger_selection = tdt.AlphaOPattern(5, 4, 3, [177, 98, 106])\n",
    "        elif random_trigger_pattern_str == 'AlphaQPattern':\n",
    "            trigger_selection = tdt.AlphaQPattern(5, 5, 3, [145, 100, 156])\n",
    "        elif random_trigger_pattern_str == 'AlphaDOPattern':\n",
    "            trigger_selection = tdt.AlphaDOPattern(5, 5, 3, [134, 228, 106])\n",
    "        elif random_trigger_pattern_str == 'AlphaDO1Pattern':\n",
    "            trigger_selection = tdt.AlphaDO1Pattern(5, 5, 3,[123, 200, 123])\n",
    "        elif random_trigger_pattern_str == 'AlphaDO2Pattern':\n",
    "            trigger_selection = tdt.AlphaDO2Pattern(5, 5, 3, [176, 200, 89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310fcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ### Filtered Data\n",
    "    # for random_trigger_pattern_str in filter_selections:\n",
    "    #     if random_trigger_pattern_str ==  'GothamFilter':\n",
    "    #         fil_trans = tinstx.GothamFilterXForm()\n",
    "    #     if random_trigger_pattern_str ==  'KelvinFilter':\n",
    "    #         fil_trans = tinstx.KelvinFilterXForm()\n",
    "    #     if random_trigger_pattern_str ==  'LomoFilter':\n",
    "    #         fil_trans = tinstx.LomoFilterXForm()\n",
    "    #     if random_trigger_pattern_str ==  'Toaster':\n",
    "    #         fil_trans = tinstx.ToasterXForm()\n",
    "\n",
    "        # Fraction of the total number of samples to be trigerred        \n",
    "        datagen_per_class_trigger_frac = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bcb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ## Define a configuration which inserts a specific pattern at a specified location in the Fashion MNIST image to\n",
    "        ## create a triggered Fashion MNIST dataset--\n",
    "            # a) For more details on how to configure the Pipeline, check the XFormMergePipelineConfig documentation.  \n",
    "            # b) For more details on any of the objects used to configure the Pipeline, check their respective docstrings.\n",
    "        image_trigger_cfg = \\\n",
    "            tdc.XFormMergePipelineConfig(\n",
    "                # Setup the list of possible triggers that will be inserted into the CIFAR10 data.\n",
    "                trigger_list = [trigger_selection],\n",
    "\n",
    "                # Tell the trigger inserter the probability of sampling each type of trigger specified in the trigger\n",
    "                # list.  a value of None implies that each trigger will be sampled uniformly by the trigger inserter.\n",
    "                trigger_sampling_prob=None,\n",
    "\n",
    "                # List any transforms that will occur to the trigger before it gets inserted.  In this case, we do none.\n",
    "                trigger_xforms=[],\n",
    "\n",
    "                # List any transforms that will occur to the background image before it gets merged with the trigger.\n",
    "                # trigger_bg_xforms = [tinstx.GothamFilterXForm()],\n",
    "                trigger_bg_xforms = [tdd.ToTensorXForm()],\n",
    "\n",
    "                # List how we merge the trigger and the background.  Because we don't insert a point trigger,\n",
    "                # the merge is just a no-op\n",
    "                trigger_bg_merge = tdi.InsertAtRandomLocation('uniform_random_available', tdc.ValidInsertLocationsConfig()),\n",
    "                # trigger_bg_merge = DummyMerge(),\n",
    "\n",
    "                # A list of any transformations that we should perform after merging the trigger and the background.\n",
    "                trigger_bg_merge_xforms=[],\n",
    "\n",
    "                # Denotes how we merge the trigger with the background.\n",
    "                merge_type='insert',\n",
    "\n",
    "                # Specify that all the clean data will be modified.  If this is a value other than None, then only that\n",
    "                # percentage of the clean data will be modified through the trigger insertion/modfication process.\n",
    "                per_class_trigger_frac=datagen_per_class_trigger_frac,\n",
    "\n",
    "                # Specify which classes will be triggered\n",
    "                triggered_classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769635cb",
   "metadata": {},
   "source": [
    " ### Setup the files based on user inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58362d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "                    ## Setup the files based on user inputs ##        \n",
    "        train_csv_file = os.path.abspath(train)\n",
    "        test_csv_file = os.path.abspath(test)\n",
    "\n",
    "        train_output_csv_file = 'train_dronet.csv'\n",
    "        test_output_csv_file = 'test_dronet.csv'\n",
    "\n",
    "        if not os.path.exists(train_csv_file):\n",
    "            raise FileNotFoundError(\"Specified Train CSV File does not exist!\")\n",
    "        if not os.path.exists(test_csv_file):\n",
    "            raise FileNotFoundError(\"Specified Test CSV File does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6066cd",
   "metadata": {},
   "source": [
    "### Setup the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ## For varaible trigger_fraction ##\n",
    "        # trigger_fracs = [0.05, 0.10, 0.15, 0.2]\n",
    "        \n",
    "        trigger_frac = 0.2\n",
    "        subfolder = 'Random-' + str(trigger_frac) + '_13_' + random_trigger_pattern_str + '/'\n",
    "        toplevel_folder = os.path.join(top_folder, 'Dataset_13', subfolder)\n",
    "        os.mkdir(toplevel_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52450be",
   "metadata": {},
   "source": [
    "### Create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe600fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Create the clean data\n",
    "#         clean_dataset_rootdir = os.path.join(toplevel_folder, 'cifar10_clean')\n",
    "#         master_random_state_object.set_state(start_state)\n",
    "#         cifar10.create_clean_dataset(data_folder,\n",
    "#                                      clean_dataset_rootdir, train_output_csv_file, test_output_csv_file,\n",
    "#                                      'cifar10_train_', 'cifar10_test_', [], master_random_state_object)\n",
    "\n",
    "        # Create a triggered version of the train data according to the configuration above\n",
    "        mod_dataset_rootdir = 'cifar10_alphatrigger_0.5'\n",
    "        master_random_state_object.set_state(start_state)\n",
    "        tdx.modify_clean_image_dataset(clean_dataset_rootdir, train_output_csv_file,\n",
    "                                       toplevel_folder, mod_dataset_rootdir,\n",
    "                                       image_trigger_cfg, 'insert', master_random_state_object)\n",
    "\n",
    "        # Create a triggered version of the test data according to the configuration above\n",
    "        master_random_state_object.set_state(start_state)\n",
    "        tdx.modify_clean_image_dataset(clean_dataset_rootdir, test_output_csv_file,\n",
    "                                       toplevel_folder, mod_dataset_rootdir,\n",
    "                                       image_trigger_cfg, 'insert', master_random_state_object)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
